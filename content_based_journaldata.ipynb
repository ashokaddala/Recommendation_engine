{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-based filtering approaches leverage description or attributes from items the user has interacted to recommend similar items. It depends only on the user previous choices, making this method robust to avoid the cold-start problem. For textual items, like articles, news and books, it is simple to use the raw text to build item profiles and user profiles. Here we are using a very popular technique in information retrieval (search engines) named TF-IDF. This technique converts unstructured text into a vector structure, where each word is represented by a position in the vector, and the value measures how relevant a given word is for an article. As all items will be represented in the same Vector Space Model, it is to compute similarity between articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3047\n",
      "3003\n"
     ]
    }
   ],
   "source": [
    "articles_df = pd.read_csv('C:\\\\Users\\\\ashok.kumar\\\\Documents\\\\rec systems\\\\shared_articles.csv\\\\shared_articles.csv')\n",
    "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
    "print(len(articles_df['title']))\n",
    "articles_df = articles_df.drop_duplicates(subset=['title'],keep= 'first')\n",
    "print(len(articles_df['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv('C:/Users/ashok.kumar/Documents/rec systems/users_interactions.csv/users_interactions.csv')\n",
    "# interactions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_strength = {\n",
    "    'VIEW' : 1.0,\n",
    "    'FOLLOW' : 2.0,\n",
    "    'BOOKMARK' : 2.5,\n",
    "    'LIKE' : 3.0,\n",
    "    'COMMENT CREATED' : 4.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_type_strength.keys(), event_type_strength.values()\n",
    "interactions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x : event_type_strength[x])\n",
    "# interactions_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\n",
    "# print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "# print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('#number of interactions: %d' % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "               how = 'right',\n",
    "               left_on = 'personId',\n",
    "               right_on = 'personId')\n",
    "# print('# number of interactions from users with at least 5 interactions: %d'\n",
    "#       % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby(['personId', 'contentId'])['eventStrength'].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()\n",
    "# print('#number of unique user/item interactions: %d' % len(interactions_full_df))\n",
    "# interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3003x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 627188 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ignoring stopwords (words with no semantics) from English and Portuguese (as we have a corpus with mixed languages)\n",
    "stopwords_list = stopwords.words('english') + stopwords.words('portuguese')\n",
    "\n",
    "#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n",
    "\n",
    "item_ids = articles_df['contentId'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(articles_df['title'] + \"\" + articles_df['text'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_profile(item_id):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids):\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profile(person_id, interactions_indexed_df):\n",
    "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\n",
    "    \n",
    "    user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1)\n",
    "    #Weighted average of item profiles by the interactions strength\n",
    "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "    return user_profile_norm\n",
    "\n",
    "def build_users_profiles(): \n",
    "    interactions_indexed_df = interactions_full_df[interactions_full_df['contentId'] \\\n",
    "                                                   .isin(articles_df['contentId'])].set_index('personId')\n",
    "    user_profiles = {}\n",
    "    for person_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profiles = build_users_profiles()\n",
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.293460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>0.247992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.239613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google</td>\n",
       "      <td>0.207207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data</td>\n",
       "      <td>0.172910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai</td>\n",
       "      <td>0.141888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>algorithms</td>\n",
       "      <td>0.103226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>graph</td>\n",
       "      <td>0.101202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>like</td>\n",
       "      <td>0.098724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>language</td>\n",
       "      <td>0.086874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>models</td>\n",
       "      <td>0.076706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>people</td>\n",
       "      <td>0.075621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>intelligence</td>\n",
       "      <td>0.074324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>use</td>\n",
       "      <td>0.073273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>deep</td>\n",
       "      <td>0.073201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>company</td>\n",
       "      <td>0.072917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>research</td>\n",
       "      <td>0.072505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.072016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>human</td>\n",
       "      <td>0.071885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>deep learning</td>\n",
       "      <td>0.071817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token  relevance\n",
       "0           learning   0.293460\n",
       "1   machine learning   0.247992\n",
       "2            machine   0.239613\n",
       "3             google   0.207207\n",
       "4               data   0.172910\n",
       "5                 ai   0.141888\n",
       "6         algorithms   0.103226\n",
       "7              graph   0.101202\n",
       "8               like   0.098724\n",
       "9           language   0.086874\n",
       "10            models   0.076706\n",
       "11            people   0.075621\n",
       "12      intelligence   0.074324\n",
       "13               use   0.073273\n",
       "14              deep   0.073201\n",
       "15           company   0.072917\n",
       "16          research   0.072505\n",
       "17             apple   0.072016\n",
       "18             human   0.071885\n",
       "19     deep learning   0.071817"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myprofile = user_profiles[-1479311724257856983]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        user_profiles[-1479311724257856983].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        #Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
    "        #Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        #Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
    "        #Ignores items the user has already interacted\n",
    "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'recStrength']) \\\n",
    "                                    .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[['contentId','recStrength', 'title']]\n",
    "            return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentBasedRecommender(articles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recStrength</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.665981</td>\n",
       "      <td>How Google is Remaking Itself as a \"Machine Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.611802</td>\n",
       "      <td>Machine Learning for Designers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579658</td>\n",
       "      <td>Machine Learning Is No Longer Just for Experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566454</td>\n",
       "      <td>How real businesses are using machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.562318</td>\n",
       "      <td>Building AI Is Hard-So Facebook Is Building AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.557759</td>\n",
       "      <td>5 Skills You Need to Become a Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.554625</td>\n",
       "      <td>Machine Learning as a Service: How Data Scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.552082</td>\n",
       "      <td>Is machine learning the next commodity?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.544568</td>\n",
       "      <td>Google's Cloud Machine Learning service is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.526078</td>\n",
       "      <td>Clarifying the uses of artificial intelligence...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recStrength                                              title\n",
       "0     0.665981  How Google is Remaking Itself as a \"Machine Le...\n",
       "1     0.611802                     Machine Learning for Designers\n",
       "2     0.579658     Machine Learning Is No Longer Just for Experts\n",
       "3     0.566454     How real businesses are using machine learning\n",
       "4     0.562318  Building AI Is Hard-So Facebook Is Building AI...\n",
       "5     0.557759  5 Skills You Need to Become a Machine Learning...\n",
       "6     0.554625  Machine Learning as a Service: How Data Scienc...\n",
       "7     0.552082            Is machine learning the next commodity?\n",
       "8     0.544568  Google's Cloud Machine Learning service is now...\n",
       "9     0.526078  Clarifying the uses of artificial intelligence..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_recommender_model.recommend_items(-1479311724257856983, topn=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
